{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW2_P4_Script.ipynb","provenance":[{"file_id":"1PPVP27QaY2HaQNW3Gy3HT8MssdqXsHbM","timestamp":1600224336543}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kWSNe8u06wUX"},"source":["# HW2 Promble 4: Linear Regression using Gradient Descent\n"]},{"cell_type":"code","metadata":{"id":"kX-xnlDMvmxu","executionInfo":{"status":"ok","timestamp":1601260979184,"user_tz":240,"elapsed":800,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6cLENr4j9-Q"},"source":["### We compute the Gradient or Partial derivative:"]},{"cell_type":"code","metadata":{"id":"bWs9aziTDDWU","executionInfo":{"status":"ok","timestamp":1601261989574,"user_tz":240,"elapsed":439,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["def step_gradient(b_current, w_current, x, y, learning_rate):\n","    b_gradient = 0\n","    w_gradient = 0\n","    N = float(len(x))\n","    for i in range(0,len(x)):\n","        b_gradient += -(2/N) * (y[i] - ((w_current * x[i]) + b_current))\n","        w_gradient += -(2/N) * x[i] * (y[i] - ((w_current * x[i]) + b_current))\n","    new_b = b_current - (learning_rate * b_gradient)\n","    new_w = w_current - (learning_rate * w_gradient)\n","    return [new_b, new_w]\n","                "],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"lilnlrFDCl-U","executionInfo":{"status":"ok","timestamp":1601260982538,"user_tz":240,"elapsed":481,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["def gradient_descent_runner(x, y, starting_b, starting_w, learning_rate, num_iterations):\n","  b = starting_b\n","  w = starting_w\n","  \n","  for i in range(num_iterations):\n","    [b, w] = step_gradient(b, w, x, y, learning_rate)\n","    print(\"After {0} iterations b = {1}, w = {2}, training error = {3}\".format(i, b, w, compute_error_for_given_points(b, w, x, y)))\n","  return [b,w]\n"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iu-7sZVeHYEL"},"source":["### We calculate the loss function using the Mean Squared Error:"]},{"cell_type":"code","metadata":{"id":"HZdkRW_gDQ_4","executionInfo":{"status":"ok","timestamp":1601262042028,"user_tz":240,"elapsed":505,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["def compute_error_for_given_points(b, w, x, y):\n","    total_error = 0\n","    for i in range(0,len(x)):\n","      total_error += (y[i] - (w * x[i] + b)) ** 2\n","    return total_error / float(len(x))"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SlfsssDZlJyp"},"source":["###Set initial parameters:"]},{"cell_type":"code","metadata":{"id":"8dQVy34e7Y_4","executionInfo":{"status":"ok","timestamp":1601260986919,"user_tz":240,"elapsed":589,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}},"outputId":"35f14a47-d21d-4577-8461-428c41d01a2d","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Make suitable changes here. My .csv file is in :  My Drive/Colab Notebooks\n","from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","%cd '/content/drive/My Drive/Colab Notebooks'\n","!pwd #Prints the present working directory"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/Colab Notebooks\n","/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bf3XsvsMh8z1","executionInfo":{"status":"ok","timestamp":1601260988504,"user_tz":240,"elapsed":550,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["#load dataset\n","dataset = pd.read_csv('petrol_consumption.csv')\n","\n","X = dataset[['Petrol_tax']]\n","y = dataset['Petrol_Consumption']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"RL1nn8FW_m-R","executionInfo":{"status":"ok","timestamp":1601260989975,"user_tz":240,"elapsed":461,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["#set learning rate\n","learning_rate = 0.0001"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyAf3rdnCLeO","executionInfo":{"status":"ok","timestamp":1601260990778,"user_tz":240,"elapsed":535,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["#slope formula:: y = wx + b\n","initial_b = 0\n","initial_w = 0"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"aEMgTR5OCSLh","executionInfo":{"status":"ok","timestamp":1601260991444,"user_tz":240,"elapsed":280,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}}},"source":["#set number of iteration\n","num_iterations = 20"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nA9h1ealVcA"},"source":["### Run Gradient descent:"]},{"cell_type":"code","metadata":{"id":"Ea5JMegWfrsD","executionInfo":{"status":"ok","timestamp":1601262046316,"user_tz":240,"elapsed":450,"user":{"displayName":"Haichen Wei","photoUrl":"","userId":"02953937478055381848"}},"outputId":"95223380-1ae4-4c21-beb9-c88c4e435936","colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["# run gradient descent with initial paramenters\n","print(\"Starting gradient descent at b = {0}, w = {1}, training error = {2}\".format(initial_b, initial_w, compute_error_for_given_points(initial_b, initial_w, X_train.to_numpy(), y_train.to_numpy())))\n","print(\"Running...\")\n","[b,w] = gradient_descent_runner(X_train.to_numpy(), y_train.to_numpy(), initial_b, initial_w, learning_rate, num_iterations)\n","print(\"After {0} iterations b = {1}, w = {2}, testing error = {3}\".format(num_iterations, b, w, compute_error_for_given_points(b, w, X_test.to_numpy(), y_test.to_numpy())))"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Starting gradient descent at b = 0, w = 0, training error = [354717.60526316]\n","Running...\n","After 0 iterations b = [0.11679474], w = [0.88114484], training error = [346864.65194069]\n","After 1 iterations b = [0.23222084], w = [1.75166263], training error = [339199.88583289]\n","After 2 iterations b = [0.3462948], w = [2.61168147], training error = [331718.79718228]\n","After 3 iterations b = [0.45903293], w = [3.46132793], training error = [324416.98430413]\n","After 4 iterations b = [0.57045132], w = [4.30072705], training error = [317290.15099663]\n","After 5 iterations b = [0.68056589], w = [5.13000234], training error = [310334.10401303]\n","After 6 iterations b = [0.78939235], w = [5.94927586], training error = [303544.7505944]\n","After 7 iterations b = [0.89694623], w = [6.75866816], training error = [296918.09606155]\n","After 8 iterations b = [1.00324287], w = [7.55829838], training error = [290450.24146462]\n","After 9 iterations b = [1.10829743], w = [8.34828418], training error = [284137.38128898]\n","After 10 iterations b = [1.21212487], w = [9.12874183], training error = [277975.80121614]\n","After 11 iterations b = [1.31474], w = [9.89978619], training error = [271961.87593832]\n","After 12 iterations b = [1.41615742], w = [10.66153073], training error = [266092.06702536]\n","After 13 iterations b = [1.51639157], w = [11.41408756], training error = [260362.92084279]\n","After 14 iterations b = [1.61545672], w = [12.15756743], training error = [254771.06651973]\n","After 15 iterations b = [1.71336696], w = [12.89207977], training error = [249313.21396558]\n","After 16 iterations b = [1.81013621], w = [13.61773268], training error = [243986.15193413]\n","After 17 iterations b = [1.90577823], w = [14.33463296], training error = [238786.74613415]\n","After 18 iterations b = [2.0003066], w = [15.04288611], training error = [233711.93738521]\n","After 19 iterations b = [2.09373474], w = [15.74259637], training error = [228758.73981772]\n","After 20 iterations b = [2.09373474], w = [15.74259637], testing error = [186882.44687047]\n"],"name":"stdout"}]}]}